{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "---\n",
    "\n",
    "# <font color=\"red\">Model Tuning with Data Flow and ADS</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Overview:\n",
    "\n",
    "Tune your models using ``ads``, ``OCI Data Flow``, and ``hyperopt``. Run through an example tuning a model locally with ``hyperopt``, then submitting that script to ``OCI Data Flow`` using ``ads``' Jobs API.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "\n",
    "- <a href='#intro'>Introduction</a>\n",
    "    - <a href=\"#setup\">Setup</a>\n",
    "- <a href='#local'>Establishing a Model Tuning Script Locally</a>\n",
    "    - <a href=\"#data\">Source Data</a>\n",
    "    - <a href=\"#tune\">Build and Tune Model on Spark</a>\n",
    "    - <a href=\"#save\">Save Model to the Catalog</a>\n",
    "- <a href=\"#remote\">Running on Data Flow</a>\n",
    "- <a href=\"#cleanup\">Clean Up</a>\n",
    "- <a href=\"#reference\">References</a>\n",
    "\n",
    "---\n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials under your agreement with Oracle.    \n",
    "\n",
    "You can access the `iris` dataset license [here](https://github.com/scikit-learn/scikit-learn/blob/master/COPYING). \n",
    "\n",
    "---\n",
    "\n",
    "The notebook is compatible with the following [Data Science conda environments](https://docs.oracle.com/en-us/iaas/data-science/using/conda_environ_list.htm):\n",
    "\n",
    "\n",
    "* [PySpark 3.0 and Data Flow](https://docs.oracle.com/en-us/iaas/data-science/using/conda-pyspark-fam.htm) for CPU on Python 3.7 (version 5.0)\n",
    "* [PySpark 3.2 and Data Flow](https://docs.oracle.com/en-us/iaas/data-science/using/conda-pyspark-fam.htm) for CPU on Python 3.8 (version 2.0)\n",
    "\n",
    "---\n",
    "\n",
    "As of February 2023, the latest PySpark env is `pyspark32_p38_cpu_v2`, which can be installed by running:\n",
    "```\n",
    "odsc conda install -s pyspark32_p38_cpu_v2\n",
    "```\n",
    "in the terminal. To check the most up to date version, visit the Environment Explorer from the Launcher Tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You may need to install hyperopt by running: `conda install -c conda-forge hyperopt`\n",
    "import os\n",
    "import pyspark\n",
    "import tempfile\n",
    "\n",
    "from hyperopt import fmin, hp, tpe\n",
    "from hyperopt import SparkTrials, STATUS_OK\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "from ads.common.model_metadata import UseCaseType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "Model tuning is an embarrassingly parallelizable process. Once you have your tuning script written with ``hyperopt``, ``ads`` can push that script onto a spark server size of your choice. We will walk through a simple example to show the configurability options and general workflow.\n",
    "\n",
    "<a id='setup'></a>\n",
    "## Setup\n",
    "\n",
    "First we need to setup the details of the environment we want to use. These are listed out in the following cell with brackets on either said \"<>\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_id = \"<compartment_id>\"  # os.environ[\"NB_SESSION_COMPARTMENT_OCID\"] # For the OCI Notebook Session \n",
    "logs_bucket_uri = \"<logs_bucket_uri>\"\n",
    "conda_pack_uri = \"oci://<conda_packs_bucket>@<conda_packs_namespace>/conda_environments/cpu/PySpark 3.2 and Data Flow/2.0/pyspark32_p38_cpu_v2\"  # If you publish your pack using the script below\n",
    "script_bucket_uri = \"oci://<script_bucket>@<script_namespace>/<optional_script_prefix>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we need to publish a conda environment with the necessary libraries. To do so from an OCI Notebook Session (recommended), run the following shell script in a terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```\n",
    "odsc conda install -s pyspark32_p38_cpu_v2\n",
    "conda activate /home/datascience/conda/pyspark32_p38_cpu_v2\n",
    "conda install -c conda-forge hyperopt\n",
    "python3 -m pip install -U oracle_ads\n",
    "odsc conda init -b <your-bucket-name> -n <your-tenancy-namespace> -a <api_key or resource_principal>\n",
    "odsc conda publish -s /home/datascience/conda/pyspark32_p38_cpu_v2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='local'></a>\n",
    "# Establishing a Model Tuning Script Locally\n",
    "\n",
    "We will load an ``sklearn`` dataset, train a simple model on it, and tune that model on a spark cluster. Then we'll combine this into 1 script, push it onto OCI Object Storage (along with our conda pack), and run our Data Flow job. ``ads`` will be able to run and watch this job all from the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Source Data\n",
    "\n",
    "We will use the iris data provided by the sklearn datasets module. Then we will Standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tune\"></a>\n",
    "## Build and Tune Model on Spark\n",
    "\n",
    "The following script will build and tune our model on a Spark cluster over the given search space. This can of course be reduced for local and increased for remote training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(params):\n",
    "    regParam = float(params['regParam'])\n",
    "    penalty = params['penalty']\n",
    "    clf = LogisticRegression(C=1.0 / regParam,\n",
    "                            multi_class='multinomial',\n",
    "                            penalty=penalty, solver='saga', tol=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "'regParam': hp.loguniform('regParam', -10.0, 0),\n",
    "}\n",
    "\n",
    "spark_trials = SparkTrials()\n",
    "best_hyperparameters = fmin(\n",
    "    fn=train,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    trials=spark_trials,\n",
    "    max_evals=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## Save Model to the Catalog\n",
    "\n",
    "Now that we've found out best parameters, let's create our model and save it to the Model Catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running with an OCI NotebookSession and have Resource Principal set up, run the folowing.\n",
    "\n",
    "from ads import set_auth\n",
    "set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "best_model = LogisticRegression(C=1.0 / best_hyperparameters['regParam'],\n",
    "                        multi_class='multinomial',\n",
    "                        penalty=('l1', 'l2')[best_hyperparameters['penalty']], solver='saga', tol=0.1).fit(X_train, y_train)\n",
    "\n",
    "model = SklearnModel(estimator=best_model, artifact_dir=artifact_dir.name)\n",
    "\n",
    "model.prepare(inference_conda_env=conda_pack_uri, force_overwrite=True, \n",
    "              use_case_type=UseCaseType.MULTINOMIAL_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving to the catalog, let's confirm our model is working using the `.verify()` method. Calling `verify` will invoke the `score.py` file of the model artifact prepared. We will calculate accuracy as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.verify(X_test)['prediction'] == y_test)/(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're happy with our model, we can push it up to the Model Catalog using the `.save()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"remote\"></a>\n",
    "# Running on Data Flow\n",
    "\n",
    "Now we can put it all together and run our script on Data Flow. The following cell writes all of the code we've gone through above into a single file, script.py. Then it uses ``ads`` to run and monitor this script as a Data Flow Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.jobs import DataFlow, Job, DataFlowRuntime\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "td = tempfile.TemporaryDirectory()\n",
    "local_script = os.path.join(td.name, \"script.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {local_script}\n",
    "import pyspark\n",
    "import tempfile\n",
    "from ads import set_auth\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "from hyperopt import fmin, hp, tpe\n",
    "from hyperopt import SparkTrials, STATUS_OK\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "    X = X.values.reshape((X.shape[0], -1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=5000, test_size=10000)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    def train(params):\n",
    "        regParam = float(params['regParam'])\n",
    "        penalty = params['penalty']\n",
    "        clf = LogisticRegression(C=1.0 / regParam,\n",
    "                                multi_class='multinomial',\n",
    "                                penalty=penalty, solver='saga', tol=0.1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'regParam': hp.loguniform('regParam', -10.0, 0),\n",
    "    }\n",
    "\n",
    "    spark_trials = SparkTrials()\n",
    "    best_hyperparameters = fmin(\n",
    "        fn=train,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        trials=spark_trials,\n",
    "        max_evals=32)\n",
    "    print(best_hyperparameters)\n",
    "\n",
    "    artifact_dir = tempfile.TemporaryDirectory()\n",
    "    best_model = LogisticRegression(C=1.0 / best_hyperparameters['regParam'],\n",
    "                            multi_class='multinomial',\n",
    "                            penalty=('l1', 'l2')[best_hyperparameters['penalty']], solver='saga', tol=0.1).fit(X_train, y_train)\n",
    "    \n",
    "    set_auth(\"resource_principal\")\n",
    "\n",
    "    model = SklearnModel(estimator=best_model, artifact_dir=artifact_dir.name)\n",
    "    model.prepare(inference_conda_env=\"pyspark32_p38_cpu_v2\", force_overwrite=True, \n",
    "                use_case_type=UseCaseType.MULTINOMIAL_CLASSIFICATION)\n",
    "    print(model.verify(X_test))\n",
    "    \n",
    "    model_id = model.save()\n",
    "    print(f\"Model ID: {model_id}\")\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"dataflow-app-{str(uuid4())}\"\n",
    "dataflow_configs = DataFlow()\\\n",
    "    .with_compartment_id(compartment_id)\\\n",
    "    .with_logs_bucket_uri(logs_bucket_uri)\\\n",
    "    .with_driver_shape(\"VM.Standard2.1\") \\\n",
    "    .with_executor_shape(\"VM.Standard2.1\") \\\n",
    "    .with_num_executors(2) \\\n",
    "    .with_spark_version(\"3.2.1\")\n",
    "runtime_config = DataFlowRuntime()\\\n",
    "    .with_script_uri(local_script)\\\n",
    "    .with_script_bucket(script_bucket_uri) \\\n",
    "    .with_custom_conda(conda_pack_uri)\n",
    "df = Job(name=name, infrastructure=dataflow_configs, runtime=runtime_config)\n",
    "df_run = df.create().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the logs and status by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run.watch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Model To Local Environment\n",
    "\n",
    "Finally, we can pull that model locally for further testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "model_reload = SklearnModel.from_model_catalog(\n",
    "    model_id,\n",
    "    artifact_dir=download_dir,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "# Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the resources from object storage, we need to create a file system instance. The following uses resource_principal, but other auth mechanisms are accepted, such as config. Then call `rm` on each file put into OCI Object Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocifs import OCIFileSystem\n",
    "\n",
    "td.cleanup()\n",
    "artifact_dir.cleanup()\n",
    "download_dir.cleanup()\n",
    "fs = OCIFileSystem()\n",
    "fs.rm(conda_pack_uri)\n",
    "fs.rm(os.path.join(script_bucket_uri, \"script.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reference\"></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v2]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
